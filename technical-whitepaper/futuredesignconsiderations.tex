
\section{Future work}

\subsubsection{Ethereum 2 and the public randomness beacon}

Ethereum 2 features several useful technologies including a public randomness beacon available per block. Randomness per block serves to replace the existing centralised design. Workers continue to snipe transactions that are known to be winning for the block immediately after, with their prizes sharing a portion of the winning amount. The process of selecting and paying a winner is similar to the process described in the off-chain distributed repeated squarings VDF beacon process, with the amount being won being matched 1-to-1 by stakers as opposed to providing a Merkle-Patricia proof.

\subsection{Off-chain distributed VDF \cite{vdf} beacon process}

\begin{center}
    \includegraphics[width=11cm]{with-vdf.png}
\end{center}

A leader is elected to produce a randomness beacon per block observed. This process is utilised on chains without public free randomness infrastructure.

\subsubsection{Beacon election}

At block-timed intervals an election with would-be randomness beacons is held on-chain. At first, aspiring beacons stake a share of their liquidity mining amounts. This staked amount is not only used to contest the right to become the leader, it is serves as an account that can be drawn down to redeem winning amounts.

A VRF is then used to develop a random number. Using the random number and the amount staked a beacon is chosen. The amount provided by the validator, staked, is slashed in the event of fraud taking place. This amount is partially deployed to serve as collateral on a per-fraud basis during the application.

\subsubsection{Beacon seeds VDF}

% loop : vdf -> block_hash -> vdf
% loop_transaction : vdf -> transaction -> vdf

The same VRF that was used to choose the beacon is then reused to seed an initial VDF. The current beacon is expected to observe transactions made on-chain.

The VDF is solved constantly by the beacon. The beacon has information on the historical number of VDF steps expected to be solved before the creation of the next block.

Per-block, several stages of the VDF is computed by taking the block hash and concatenating it with the previous VDF output. This serves as the source of randomness that each transaction is compared against to determine if a winner was discovered.

\subsubsection{Winner discovery and redemption}

Upon discovering a winner, the beacon may share the randomness for the block to a group of workers known as the validator group. It may also optionally begin the process of redeeming a winner itself.

To redeem a winner, the party redeeming the prize must match the amount that was to be awarded to the winning user 1-to-1. To do so they supply the VRF, the transaction hash and a user's address. Validation of the VRF takes place, confirming the generation was appropriate.

Once this amount is backed 1-to-1, the payout happens immediately and the provided amount by the party redeeming the prize is locked up for a period.

At any point during this period, a party may use staked funds to allege that a winner should not have been awarded. The staked funds provided by the party alleging fraud is staked until another party (or the party redeeming the winner) contests the allegation. The allegation is contested by providing a Merkle-Patricia proof for the transaction in question.

Upon disproving a fraud allegation, the party alleging fraud has its amounts slashed and the submitter of the check receives a small amount as compensation.

\subsubsection{Validator group}

The validator group serves to prevent fraud taking place and to support the redemption of winners. Due to the heavy capital requirements of redeeming winners, the beacon developing the randomness may utilise the validator group to submit winning transactions. The beacon distributes the current VDF state to the validator group which independently validates the VDF and per transaction randomness. The validator group, having previously staked funds themselves, may redeem winners that were discovered by the VDF generated by the beacon. In doing so, the beacon receives a small amount as compensation for discovering the winning amount. This system incentivises a lighter-on-capital strategy for simply discovering winners by solving a VDF and other people solving it for compensation.

\subsubsection{End of life}

At the end of the period, the beacon must submit the VRF for each stage leading up to the final block for their period (excluding the ones submitted previously when redeeming winners). Each stage can be validated and challenged by another party using a similar mechanism as previous. Any validator may cross-reference the VRF with each transaction taken place in a previous block and back the amount paid out 1-to-1 during this period with the same winner redemption algorithm. Optionally, transaction batching can take place.

\subsubsection{Attack vectors}

Multiple attack vectors are considered. An attacker might solve a VDF stage then precompute the next and generate a block that, combined with the VDF, leads to a winner. To mitigate this, the difficulty

\subsubsection{Winning transaction batching}

Transactions that previously won small amounts can be aggregated and reported as winning in a batch after the end of life period. Due to these transactions not being rewarded immediately in the past, the UX constraint on immediate rewards has been violated. Transaction details are aggregated, with the submitter of the transactions providing staked amount collateral to be slashed if fraud occurs. The worker in this context is known as the "aggregating worker". Other workers, observing this transaction batching can front a bond and challenge the submitter of the aggregation claiming that a transaction was irredeemable. During this period, the aggregating worker can submit a proof that the transaction took place and was winning. If the reply to the fraud check is submitted and is valid, the proof worker bond will be slashed. If fraud did take place, the proving worker is rewarded by the tokens provided by the aggregating worker.

\subsection{Cleaning the buffer}

Regular maintenance of the contract is needed to reduce storage on-chain. Maintenance is eliminating transactions stored in the buffer that were made before the last 256 blocks. A function will be provided to automate this process and it will be managed by the DAO, then the community.

\subsection{Graph classification strategy}

For low gas fee blockchains with limited contextual understanding of transactions between users, a graph strategy is developed. This is similar to Kaggle, a competition hosting website held frequently. The DAO submits a challenge set, and competitors submit a "solution" to the challenge set, seeking to outperform the current baseline for graph classification.

Transactions in clusters can be seen to follow specific patterns. Algorithms compete to take these existing clusters and to classify them as "neighbourhoods" based on the amount of excess "energy". Excess energy is computed as the number of "dangling" transactions.

A dangling transaction is where Andy sends money to Bob and Bob sends money to Calvin and Calvin hoards the money. The energy of the transaction relationship appears as such:

\begin{center}
    \includegraphics[width=11cm]{excess-energy.png}
\end{center}

As the transaction graph features three disparate vertices, Andy, Bob and Calvin, Andy as the progenitor has an energy of 0. Andy initiated the transaction that saw the other two entities in the graph, with his transaction making up the life of the network. Bob however has some excess energy, as his transaction would reach one other party in the graph. Calvin hoards his money so his energy does not effect the other entities in this graph. In a broader scope, small clusters of transactions can begun to be thought of as neighbourhoods. Neighbourhoods are simplified transaction graphs with a quantifiable measure of the excess energy attached.

At regular intervals, algorithms attempt to discover the optimal combination of neighbourhoods based on the amount of excess energy in each neighbourhood. Various parameters are tweaked within the DAO according to constraints identified by the community; these include the target excess energy amount, any premiums awarded to "blessed" contracts and addresses (ie, known contracts that are considered common infrastructure) with weights. These neighbourhoods affect the expected outcome of any funds contained within, with an off-chain worker classifying the transaction per trade with an oracle serving any claims. These classifications are used to inform the expected outcome for any future transactions that mirror the existing graph.

An example:

\begin{center}
    \includegraphics[width=11cm]{neighbourhoods.png}
\end{center}

Workers that compete to submit the optimal neighbourhood design do so under the premise that they will be elected "mayors" for a period. Mayors receive a small fee paid out for each transaction during the period of their lordship until the next election process. Optimal neighbourhood design will be developed in research in the future. The DAO will design constraints and targets based on data collected from real-world use, informing future constraints.

\subsection{Sell-down of expected outcomes and outcome farming}

Expected outcomes can be immediately sold down to provide infrastructure for cashback rewards similar to a credit card reward process. The sell-down of expected outcomes is facilitated by a dutch auction held on an optimistic off-chain process. Parties transacting using Fluid Assets could enter into purchase agreements with external parties to always supply the purchaser with the expected outcomes at a fixed amount. These purchase agreements could be supplied to processes including Alchemix \cite{alchemix} and Pendle \cite{pendle} to see immediate yield on any amounts.

\subsection{Fluidity language}

Fluidity features two design primitives: first, the "seeding" of an expense and second the event triggering a drawing process. The seeding of the expense informs the drawing process held by the second UX constraint, with the reward probability quantified by a hardcoded constraint and the expense seeded.

In the above process, an amount is paid as the gas and the contract fee (if any). This amount manifests itself as state refereed to by the second primitive, the transfer. The transfer takes a single argument, a modifier that states that the full amount of seeded expense should be considered when developing the randomness for this process.

\subsubsection{Diagrammatic programming}

This process suits in the case of a simple transfer. But as Fluid Assets encapsulate many an asset in their different forms (bonds, options, swaps), a new design language is required. This process manifests itself as a diagram and state machine language that serves to generate integration templates for would-be partners.

